---
title: File Formats
description: Guide on how to format input files for RunRL
---

## Prompt Files

Prompt files contain the examples that your model will learn from during training. They define the inputs that will be sent to the model.

### Format Requirements

Prompt files must be in JSONL (JSON Lines) format, with each line containing a complete, valid JSON object. The file extension should be `.jsonl`.

### Required Structure

Each line in your prompt file must include:

- `prompt`: An array of message objects, where each message has:
  - `role`: The role of the speaker (e.g., "system", "user", "assistant")
  - `content`: The actual message text

### Additional Fields

You can include additional fields that your reward function might need for evaluation. Common examples include:
- `expected_result`: The expected answer or output
- `difficulty`: A difficulty level indicator
- `category`: A categorization tag
- Any custom metadata your reward function requires

### Example Prompt File

```jsonl
{"prompt":[{"role":"system","content":"You are an expert at mathematics."},{"role":"user","content":"What is the value of this expression: { ((54 - 140 * 118 + 130) + 197) + 46 }? Think for as long as you want, and then give your answer inside of <answer></answer> XML tags."}],"expected_result":-16093}
{"prompt":[{"role":"system","content":"You are an expert at mathematics."},{"role":"user","content":"What is the value of this expression: { (56 + 141 + 74) + 135 }? Think for as long as you want, and then give your answer inside of <answer></answer> XML tags."}],"expected_result":406}
{"prompt":[{"role":"system","content":"You are an expert at mathematics."},{"role":"user","content":"What is the value of this expression: { (194 + 92 + 120) + 26 - 22 }? Think for as long as you want, and then give your answer inside of <answer></answer> XML tags."}],"expected_result":410}
```

### Best Practices

- Each line must be a complete, valid JSON object
- No trailing commas are allowed between lines
- Include a diverse distribution of prompts that represent your use case
  - Generally, aim for at least 100 distinct examples for effective training
- Consider including difficulty levels or categories if your task has natural groupings

## Reward Functions

Reward functions evaluate the model's responses and provide feedback signals that guide the learning process. They determine how well the model is performing on your task.

### Core Concepts

A reward function:
- Receives the model's completion/response, along with any additional fields from the prompt file (like expected answers)
- Evaluates the quality of that response
- Returns a numerical score

### Reward Design Principles

- **Varied Scores**: Ensure your reward function produces a range of values. If all responses get the same reward, the model cannot learn to distinguish good from bad.
- **Clear Signal**: Higher rewards should consistently indicate better performance
- **Balanced Feedback**: Consider both rewarding desired behaviors and penalizing undesired ones
- **Robust Evaluation**: Handle edge cases and unexpected inputs gracefully
- **Low Hackability**: Make it difficult for the model to cheat the reward function

### Implementation Languages

For language-specific implementation details, see:
- [Python Implementation Guide](/python/file-formats#reward-functions)

## Environment Classes

Environment classes create interactive scenarios where the model's actions affect the state and receive feedback through observations and rewards. They're useful for sequential decision-making tasks.

### Core Concepts

An environment:
- Maintains internal state across interactions
- Receives actions from the model
- Returns observations, rewards, and termination signals
- Resets between episodes

### Key Components

1. **Initialization**: Sets up the initial state for each episode
2. **Step Function**: Processes actions and returns feedback
3. **Termination Logic**: Determines when an episode ends
4. **Reward Structure**: Provides appropriate feedback for learning

### Implementation Languages

For language-specific implementation details, see:
- [Python Implementation Guide](/python/file-formats#environment-classes)

## General Best Practices

### For All File Types
- Test your files before starting training runs
- Use version control to track changes to your prompt files and reward functions
- Document your reward criteria and environment logic clearly
- Start with simple implementations and iterate based on results

### For Effective Learning
- Ensure reward signals are informative (not all zeros or all maximum values)
- Provide a good distribution of examples in your prompt files
- Balance difficulty to maintain a learning gradient
- Monitor training metrics to verify the model is learning as expected